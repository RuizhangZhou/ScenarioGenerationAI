{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb67f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim #优化\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #绘图\n",
    "import torchvision #加载图片\n",
    "from torchvision import transforms #图片变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ab00164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据做归一化（-1，1）\n",
    "transform=transforms.Compose([\n",
    "    #将shanpe为（H,W,C）的数组或img转为shape为（C,H,W）的tensor\n",
    "    transforms.ToTensor(), #转为张量并归一化到【0，1】；数据只是范围变了，并没有改变分布\n",
    "    transforms.Normalize(0.5,0.5)#数据归一化处理，将数据整理到[-1,1]之间；可让数据呈正态分布\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88aaae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载数据到指定的文件夹\n",
    "train_ds = torchvision.datasets.MNIST('data',\n",
    "                                      train=True,\n",
    "                                     transform=transform,\n",
    "                                     download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "490e62a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6430f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=torch.utils.data.DataLoader(train_ds,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cad6d973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d8a7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.main=nn.Sequential(\n",
    "        nn.Linear(100,256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256,512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512,784),\n",
    "        nn.Tanh()#对于生成器，最后一个激活函数是tanh,值域：-1到1\n",
    "        )\n",
    "    #定义前向传播 \n",
    "    def forward(self,x):  #x表示长度为100的noise输入\n",
    "        img = self.main(x)\n",
    "        img=img.view(-1,28,28)#转换成图片的形式\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "        nn.Linear(784,512),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(512,256),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(256,1),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        x =x.view(-1,784) #展平\n",
    "        x =self.main(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57d44049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设备的配置\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aba8f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化生成器和判别器把他们放到相应的设备上\n",
    "gen = Generator().to(device)\n",
    "dis = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a97c3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训判别的优化器\n",
    "d_optim = torch.optim.Adam(dis.parameters(),lr=0.0001)\n",
    "#生成器的优化器\n",
    "g_optim = torch.optim.Adam(gen.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6955527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#交叉熵损失函数\n",
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77a6a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_img_plot(model,test_input):\n",
    "    prediction = np.squeeze(model(test_input).detach().cpu().numpy())\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow((prediction[i]+1)/2)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24370428",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn(16,100 ,device=device) #16个长度为100的随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdc12a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0763, -1.1435,  1.5656,  ...,  1.0905, -1.0033, -1.1867],\n",
       "        [-1.1210, -0.8359, -0.8875,  ..., -0.7684,  2.1233, -0.1949],\n",
       "        [ 0.3961,  0.0162,  0.2323,  ...,  0.8971,  1.6186, -0.1123],\n",
       "        ...,\n",
       "        [-1.9438,  0.8925, -2.2009,  ..., -0.7211, -0.7498,  1.4684],\n",
       "        [ 0.5039, -0.2639,  0.3243,  ..., -0.5516, -0.4858, -0.4801],\n",
       "        [ 1.0587,  0.3090, -0.7299,  ..., -0.9110, -0.6720,  1.4128]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f07d4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = []\n",
    "G_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa271459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5.8859e-01,  1.0350e+00,  6.8039e-01,  ...,  1.6168e-01,\n",
      "           -6.7795e-01,  7.5331e-01],\n",
      "          [-6.5857e-01, -4.9416e-01,  8.9317e-01,  ..., -5.8640e-01,\n",
      "            4.6694e-01, -7.5501e-01],\n",
      "          [-2.7218e-01, -1.1747e+00, -1.6233e-01,  ..., -6.7540e-02,\n",
      "            1.0825e+00, -2.3239e+00],\n",
      "          ...,\n",
      "          [ 2.7116e-01, -1.7746e+00, -4.0763e-01,  ...,  8.3252e-02,\n",
      "           -3.5186e-02, -5.0943e-01],\n",
      "          [ 2.0324e+00, -3.1742e-01, -5.5589e-01,  ...,  1.2065e+00,\n",
      "           -4.2902e-01, -1.6424e+00],\n",
      "          [ 9.7063e-01, -9.4635e-01,  8.3306e-01,  ..., -6.7712e-01,\n",
      "            7.7423e-01,  2.8509e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8613e-01, -1.5481e+00,  9.0484e-01,  ..., -9.4380e-01,\n",
      "           -1.0355e-02,  1.6323e+00],\n",
      "          [-1.7574e-01,  2.2762e+00, -1.1247e+00,  ..., -8.2487e-01,\n",
      "           -6.8479e-02, -2.1899e+00],\n",
      "          [ 2.4791e+00, -2.7252e-01, -1.4296e+00,  ...,  1.2965e+00,\n",
      "            1.3801e+00, -2.1804e+00],\n",
      "          ...,\n",
      "          [-1.4444e+00, -1.0121e+00, -1.3866e+00,  ...,  1.2743e+00,\n",
      "           -5.2051e-03, -6.2754e-01],\n",
      "          [ 7.4135e-01, -1.9245e+00,  5.5298e-01,  ..., -1.0467e+00,\n",
      "            9.6304e-01,  3.5129e-02],\n",
      "          [-1.1238e+00,  7.9265e-01, -4.1852e-01,  ...,  4.9742e-02,\n",
      "            1.8471e+00,  4.1066e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9908e-01,  4.6487e-01, -5.4771e-02,  ...,  1.1710e+00,\n",
      "            8.3145e-01,  6.9243e-01],\n",
      "          [-7.7126e-01,  1.5684e+00, -4.8821e-01,  ..., -2.7313e-01,\n",
      "           -1.0364e+00,  5.3562e-02],\n",
      "          [ 9.1355e-01,  9.0594e-02, -8.8442e-02,  ...,  1.2481e-01,\n",
      "            1.6494e-01,  1.5384e-01],\n",
      "          ...,\n",
      "          [-1.0877e-01,  4.2218e-01,  4.0141e-04,  ...,  6.6760e-01,\n",
      "           -6.2646e-01,  3.2990e-01],\n",
      "          [-1.4025e+00, -6.5313e-01, -1.0385e+00,  ...,  9.8757e-02,\n",
      "           -2.6827e-01, -2.1842e-01],\n",
      "          [-4.7741e-02, -2.0510e-01, -6.0697e-01,  ...,  4.2366e-01,\n",
      "           -4.7264e-01,  2.0342e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3215e+00,  2.0642e+00, -4.7861e-01,  ...,  2.0080e+00,\n",
      "           -6.8312e-01, -4.0697e-01],\n",
      "          [-1.7886e+00,  8.4911e-01, -9.9724e-02,  ...,  4.7549e-01,\n",
      "           -1.8091e+00,  2.3622e-01],\n",
      "          [-1.5101e+00, -4.8500e-01,  2.6530e+00,  ...,  5.8920e-01,\n",
      "           -5.8612e-01,  6.9094e-01],\n",
      "          ...,\n",
      "          [-7.6054e-01, -1.1149e+00, -1.8792e-01,  ...,  5.5340e-01,\n",
      "            1.2347e-02,  3.5602e-01],\n",
      "          [ 4.3770e-01, -1.7162e-01, -6.5705e-01,  ..., -7.3768e-02,\n",
      "           -5.2045e-01, -1.5455e+00],\n",
      "          [ 3.4297e-02,  7.2185e-01,  4.5796e-01,  ...,  2.2940e-02,\n",
      "           -5.8253e-01, -7.2345e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6459e-01,  8.9508e-01,  1.1546e+00,  ..., -4.3113e-01,\n",
      "           -2.5728e-01,  1.6881e+00],\n",
      "          [-2.2222e+00,  1.1428e+00, -6.5718e-01,  ..., -7.0645e-02,\n",
      "           -6.4094e-01, -1.1253e-01],\n",
      "          [-3.3635e-01,  3.7919e-01,  2.7366e-01,  ...,  2.8210e-01,\n",
      "           -9.6228e-01,  1.7230e+00],\n",
      "          ...,\n",
      "          [-8.8244e-01, -1.1166e+00, -6.5780e-01,  ...,  2.3599e+00,\n",
      "            4.6486e-01, -1.2247e+00],\n",
      "          [ 1.0886e+00, -1.5625e-01,  9.8448e-01,  ..., -1.1526e+00,\n",
      "           -3.3816e-01, -5.6097e-01],\n",
      "          [ 4.6806e-01, -1.6079e+00,  4.5109e-01,  ...,  1.7641e-01,\n",
      "           -1.8343e+00, -3.3118e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4363e-01,  4.7428e-01, -1.6410e-01,  ..., -1.1722e-01,\n",
      "           -5.5919e-01, -6.4116e-01],\n",
      "          [ 2.6184e-01,  7.8109e-01,  6.4685e-01,  ..., -1.7677e+00,\n",
      "            4.8400e-01, -1.1834e+00],\n",
      "          [ 7.5088e-01, -1.6554e+00, -8.9106e-01,  ..., -3.7850e-01,\n",
      "           -9.5686e-02, -1.5346e+00],\n",
      "          ...,\n",
      "          [-8.9896e-01,  5.7701e-01,  4.3179e-01,  ..., -1.6688e-01,\n",
      "           -1.5422e-03, -5.8277e-01],\n",
      "          [-6.1767e-01,  4.2807e-01, -1.4636e+00,  ...,  7.7593e-01,\n",
      "           -3.3417e-01, -4.0031e-01],\n",
      "          [ 1.0198e+00,  5.9618e-01,  8.0638e-01,  ...,  4.5974e-02,\n",
      "           -5.8490e-01,  1.3201e+00]]]], device='cuda:0')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.randn([64, 1, 28, 28],device=device)\n",
    "print(random_tensor)\n",
    "output=dis(random_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c38d8b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m real_output \u001b[38;5;241m=\u001b[39m dis(img) \u001b[38;5;66;03m#判别器输入真实的图片，real_output对真实图片的预测结果\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(real_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     19\u001b[0m d_real_loss \u001b[38;5;241m=\u001b[39m loss_fn(real_output,\n\u001b[1;32m     20\u001b[0m                       torch\u001b[38;5;241m.\u001b[39mones_like(real_output)\n\u001b[1;32m     21\u001b[0m                       )\n\u001b[1;32m     22\u001b[0m d_real_loss\u001b[38;5;241m.\u001b[39mbackward()\u001b[38;5;66;03m#计算梯度\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#训练循环\n",
    "for epoch in range(20):\n",
    "    #初始化损失值\n",
    "    d_epoch_loss = 0\n",
    "    g_epoch_loss = 0\n",
    "    count = len(dataloader) #返回批次数\n",
    "    #对数据集进行迭代\n",
    "    for step,(img,_) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        size = img.size(0) #img的第一位是size,获取批次的大小(64)\n",
    "        random_noise = torch.randn(size,100,device=device)\n",
    "        \n",
    "        #判别器训练(真实图片的损失和生成图片的损失),损失的构建和优化\n",
    "        d_optim.zero_grad()#梯度归零\n",
    "        #判别器对于真实图片产生的损失\n",
    "        real_output = dis(img) #判别器输入真实的图片，real_output对真实图片的预测结果\n",
    "        #import pdb; pdb.set_trace()\n",
    "        print(real_output.shape)\n",
    "        d_real_loss = loss_fn(real_output,\n",
    "                              torch.ones_like(real_output)\n",
    "                              )\n",
    "        d_real_loss.backward()#计算梯度\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        gen_img = gen(random_noise) #得到生成的图片\n",
    "        #因为优化目标是判别器，所以对生成器上的优化目标进行截断\n",
    "        fake_output = dis(gen_img.detach()) #判别器输入生成的图片，fake_output对生成图片的预测;detach会截断梯度，梯度就不会再传递到gen模型中了\n",
    "        #判别器在生成图像上产生的损失\n",
    "        d_fake_loss = loss_fn(fake_output,\n",
    "                              torch.zeros_like(fake_output)\n",
    "                              )\n",
    "        d_fake_loss.backward()\n",
    "        #判别器损失\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        #判别器优化\n",
    "        d_optim.step()\n",
    "        \n",
    "        \n",
    "        #生成器上损失的构建和优化\n",
    "        g_optim.zero_grad() #先将生成器上的梯度置零\n",
    "        fake_output = dis(gen_img)\n",
    "        g_loss = loss_fn(fake_output,\n",
    "                              torch.ones_like(fake_output)\n",
    "                          )  #生成器损失\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "        #累计每一个批次的loss\n",
    "        with torch.no_grad():\n",
    "            d_epoch_loss +=d_loss\n",
    "            g_epoch_loss +=g_loss\n",
    "    #求平均损失\n",
    "    with torch.no_grad():\n",
    "            d_epoch_loss /=count\n",
    "            g_epoch_loss /=count\n",
    "            D_loss.append(d_epoch_loss)\n",
    "            G_loss.append(g_epoch_loss)\n",
    "            print('Epoch:',epoch)\n",
    "            gen_img_plot(gen,test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7ab54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
